batch_size: 16
iters: 20000

model:
  type: CX_Uper_2B1
  backb: convnext_small
  in_channels: 3
  num_classes: 14
  dropout_rate: 0

# loss:
#   types:
#     - type: MixedLoss
#       losses:
#         - type: CrossEntropyLoss_Smooth
#           smoothing: 0.05
#         - type: DiceLoss
#       coef: [1, 0.5]
#   coef: [1]
loss:
  types:
    - type: CrossEntropyLoss
  coef: [1]


optimizer:
  type: AdamW

lr_scheduler:
  type: StepDecay
  learning_rate: 0.02
  step_size: 3000
  gamma: 0.5


train_dataset:
  type: RS_MD2B
  dataset_root: /home/aistudio/data/src/C2Seg_AB/train/
  train_path:  /home/aistudio/data/src/train.txt
  num_classes: 14
  transforms:
    - type: Normalize2
      mean1: [511.299, 664.096, 769.063, 2714.783]
      mean2: [-15.968, -24.246]
      std1:  [377.968, 454.927, 509.648, 663.224]
      std2:  [4.606, 4.104]
  mode: train

val_dataset:
  type: RS_MD2B
  dataset_root: /home/aistudio/data/src/C2Seg_AB/train/
  val_path:  /home/aistudio/data/src/val.txt
  num_classes: 14
  transforms:
    - type: Normalize2
      mean1: [511.299, 664.096, 769.063, 2714.783]
      mean2: [-15.968, -24.246]
      std1:  [377.968, 454.927, 509.648, 663.224]
      std2:  [4.606, 4.104]
  mode: val





# 682.8222280649038	904.1583766168727	855.6306981795873	2714.7835360237095	261.79564319322594	259.42994616536953	347.27061044533224	669.844619319619
# -15.958288192749023	-9.107815742492676	3.9245078563690186	4.6198015213012695

# 511.29928066136125	664.0968298113313	769.0629001884568	1248.1036750237815	377.96860512147674	454.92702423563065	509.64776482004817	663.2246271166581
# -15.96798038482666	-24.24662208557129	4.60582971572876	4.104198932647705

# 2.677734227705505	3.545719123987736	3.3554145026650484	10.646209945191018	1.0266495811499055	1.0173723379034099	1.3618455311581656	2.626841644390663
# -0.06258152980430454	-0.035716924480363434	0.015390226887721641	0.01811686684103573

# 0.26777342277055055	0.35457191239877356	0.33554145026650506	1.0646209945191019	0.10266495811499242	0.10173723379034107	0.13618455311581357	0.2626841644390632
# 0.6258153578814338	0.35716920740464153	0.15390227074716606	0.1811686347512638
